{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import rpy2.robjects.lib.ggplot2 as ggplot2\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "base = importr('base')\n",
    "\n",
    "# the base of rpy2 plotting is matplotlib, thus we need to declare\n",
    "# it inline in order to see the plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# we need to activate the automatic conversion for pandas\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "# load the needed extension for the %%R cell magic\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "plt.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = \"~/burrito\"\n",
    "outdirs = [\"kv-cloudlab-a386584\"]\n",
    "datapaths = ['kernel', 'dpdkthread', 'dpdkmulti', 'shenango_channel']\n",
    "#num_shards = [2, 4, 6, 8]\n",
    "num_shards = [4,]\n",
    "#ops = [1000, 5000, 10000, 20000, 40000, 60000, 80000, 100000, 160000, 200000, 240000, 320000]\n",
    "ops = [10000, 20000, 40000, 60000, 80000, 100000, 120000, 140000, 160000, 180000, 200000]\n",
    "#clients = ['10.1.1.3', '10.1.1.4', '10.1.1.5']\n",
    "clients = ['10.10.1.1']\n",
    "#shard_types = ['client', 'server', 'basicclient']\n",
    "shard_types = ['client']\n",
    "client_concurrency = [4, 8]\n",
    "poisson = [True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: this aggregates requestclients together\n",
    "\n",
    "@ray.remote\n",
    "def read_exp(outdir, dp, ns, st, o, p, c):\n",
    "    def get_clients():\n",
    "        for cl in clients:\n",
    "            fn = f\"{rootdir}/{outdir}/{dp}-{ns}-{st}shard-{o}-poisson={p}-workloadb-{c}-0-client0-{cl}.data\"\n",
    "            try:\n",
    "                df_file = pd.read_csv(fn, sep=\" \")\n",
    "                df_file[\"ShardType\"] = st\n",
    "                df_file['NumShards'] = ns\n",
    "                df_file[\"Ops\"] = o\n",
    "                df_file = df_file[(df_file.NumOps > 200e3) & (df_file.NumShards > 1)]\n",
    "                yield df_file\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "    \n",
    "    try:\n",
    "        exp_df = pd.concat(get_clients())\n",
    "    except Exception:\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    # now calculate this experiment's stats.\n",
    "    exp_stats = exp_df.groupby([\"ShardType\", \"NumShards\", \"Ops\"]).quantile([0.05, 0.25, 0.5, 0.75, 0.95])\n",
    "    exp_stats = exp_stats.unstack()\n",
    "    exp_stats.columns = [f\"{s}_{t}\" for s,t in exp_stats.columns.values]\n",
    "    exp_stats.columns.to_flat_index()\n",
    "    exp_stats[\"Commit\"] = outdir\n",
    "    exp_stats[\"Datapath\"] = dp\n",
    "    exp_stats[\"Concurrency\"] = c\n",
    "    exp_stats[\"Poisson\"] = p\n",
    "    return exp_stats\n",
    "\n",
    "def combos():\n",
    "    for outdir in outdirs:\n",
    "        for dp in datapaths:\n",
    "            for ns in num_shards:\n",
    "                for st in shard_types:\n",
    "                    for o in ops:\n",
    "                        o = int(o)\n",
    "                        for p in poisson:\n",
    "                            for c in client_concurrency:\n",
    "                                yield read_exp.remote(outdir, dp, ns, st, o, p, c)\n",
    "\n",
    "exp_dfs = ray.get([x for x in combos()])\n",
    "df = pd.concat(exp_dfs)\n",
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i df -w 900 -h 600\n",
    "\n",
    "library(ggplot2)\n",
    "\n",
    "#geom_boxplot(aes(group=interaction(ShardType,Ops)), position=\"dodge\") + \n",
    "#ggplot(pdf, aes(x=Ops, y=Latency_us, \n",
    "#  fill=ShardType, group=interaction(ShardType,Ops))) + \n",
    "#    stat_summary(fun.data = f, geom=\"boxplot\", position=\"dodge\") + \n",
    "#    facet_grid(NumShards~Concurrency) +\n",
    "#    coord_cartesian(ylim=c(0, 10000))\n",
    "\n",
    "ggplot(df, aes(x=Ops, fill=Datapath, group=interaction(Datapath,Ops))) +\n",
    "  geom_errorbar(aes(ymin=Latency_us_0.05, ymax = Latency_us_0.95), position=\"dodge\") +\n",
    "  geom_crossbar(aes(ymin=Latency_us_0.25, y=Latency_us_0.5, ymax = Latency_us_0.75), position=\"dodge\") +\n",
    "  coord_cartesian(ylim=c(0, 350)) + facet_wrap(~Concurrency)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i df -w 1200 -h 400\n",
    "\n",
    "df$kOps <- df$Ops / 1e3\n",
    "df <- df[df$kOps == 40 | df$kOps == 80 | df$kOps == 120 | df$kOps == 160 | df$kOps == 200,]\n",
    "\n",
    "df$nego <- grepl(\"_no\", df$Datapath, fixed=TRUE)\n",
    "\n",
    "#labs <- c(\n",
    "#    \"kernel\" = \"Linux\",\n",
    "#    \"kernel_noneg\" = \"Linux-N\",\n",
    "#    \"dpdk\" = \"DPDK\",\n",
    "#    \"dpdk_noneg\" = \"DPDK-N\",\n",
    "#    \"shenango_channel\" = \"Shenango (Ad.)\",\n",
    "#    \"shenango_channel_noneg\" = \"Shenango (Ad.)-N\",\n",
    "#    \"shenango_rt\" = \"Shenango (Rt.)\",\n",
    "#    \"shenango_rt_noneg\" = \"Shenango (Rt.)-N\",\n",
    "#    \"shenango_rt_nochunnels\" = \"Shenango-C\"\n",
    "#)\n",
    "#values = c(\n",
    "#    \"dpdk\" = \"#1f78b4\",\n",
    "#    \"dpdk_noneg\" = \"#a6cee3\",\n",
    "#    \"kernel\" = \"#e31a1c\",\n",
    "#    \"kernel_noneg\" = \"#fb9a99\",\n",
    "#    \"shenango_channel\" = \"#33a02c\",\n",
    "#    \"shenango_channel_noneg\" = \"#b2df8a\",\n",
    "#    \"shenango_rt\" = \"#006d2c\",\n",
    "#    \"shenango_rt_noneg\" = \"#74c476\",\n",
    "#    \"shenango_rt_nochunnels\" = \"#aaaaaa\"\n",
    "#),\n",
    "labs <- c(\n",
    "    \"kernel\" = \"Linux\",\n",
    "    \"kernel_noneg\" = \"Linux\",\n",
    "    \"dpdk\" = \"DPDK\",\n",
    "    \"dpdk_noneg\" = \"DPDK\",\n",
    "    \"shenango_channel\" = \"Shenango-A\",\n",
    "    \"shenango_channel_noneg\" = \"Shenango-A\",\n",
    "    \"shenango_rt\" = \"Shenango-R\",\n",
    "    \"shenango_rt_noneg\" = \"Shenango-R\",\n",
    "    \"shenango_rt_nochunnels\" = \"Baseline\"\n",
    ")\n",
    "\n",
    "df$lab <- labs[df$Datapath]\n",
    "\n",
    "ggplot(df, aes(x=as.factor(kOps), label=lab, color=Datapath, group=interaction(Datapath,lab,kOps))) +\n",
    "geom_errorbar(aes(ymin=Latency_us_0.05, ymax = Latency_us_0.95), position=\"dodge\") +\n",
    "geom_crossbar(aes(ymin=Latency_us_0.25, y=Latency_us_0.5, ymax = Latency_us_0.75), position=\"dodge\") +\n",
    "geom_text(aes(y=100), angle=90, position=position_dodge(width=0.9), show.legend=FALSE) +\n",
    "facet_wrap(~nego) +\n",
    "scale_color_manual(\n",
    "    labels = labs,\n",
    "    values = c(\n",
    "        \"dpdk\" = \"#1f78b4\",\n",
    "        \"dpdk_noneg\" = \"#1f78b4\",\n",
    "        \"kernel\" = \"#e31a1c\",\n",
    "        \"kernel_noneg\" = \"#e31a1c\",\n",
    "        \"shenango_channel\" = \"#33a02c\",\n",
    "        \"shenango_channel_noneg\" = \"#33a02c\",\n",
    "        \"shenango_rt\" = \"#006d2c\",\n",
    "        \"shenango_rt_noneg\" = \"#006d2c\",\n",
    "        \"shenango_rt_nochunnels\" = \"#aaaaaa\"\n",
    "    ),\n",
    ") +\n",
    "coord_cartesian(ylim=c(0, 350)) +\n",
    "xlab(\"Offered Load kOp/sec\") + ylab(\"Request Latency (Î¼s)\") +\n",
    "theme_minimal() +\n",
    "theme(\n",
    "    legend.position = \"top\",\n",
    "    legend.title=element_blank(),\n",
    "    text = element_text(size=12, family=\"IBM Plex Sans\", face=\"bold\"),\n",
    "    axis.text.y = element_text(size=12, family=\"IBM Plex Sans\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./kv-datapaths-2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Batch Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "read_sizes = re.compile(r\"client_id=([0-9]+).*p5=([0-9]+) p25=([0-9]+) p50=([0-9]+) p75=([0-9]+) p95=([0-9]+) cnt=([0-9]+)\")\n",
    "\n",
    "def batch_sizes(fn):\n",
    "    x = []\n",
    "    with open(fn, 'r') as f:\n",
    "        for line in f:\n",
    "            if \"send_batch_size\" not in line:\n",
    "                continue\n",
    "            m = read_sizes.search(line)\n",
    "            x.append({\n",
    "                'client_id': m.group(1), \n",
    "                'p5': int(m.group(2)),\n",
    "                'p25': int(m.group(3)),\n",
    "                'p50': int(m.group(4)),\n",
    "                'p75': int(m.group(5)),\n",
    "                'p95': int(m.group(6)),\n",
    "                'cnt': int(m.group(7))\n",
    "            })\n",
    "    return x\n",
    "        \n",
    "\n",
    "batch_size_data = None\n",
    "for outdir in outdirs:\n",
    "    for ns in num_shards:\n",
    "        for o in ops:\n",
    "            o = int(o)\n",
    "            for st in shard_types:\n",
    "                for cl in clients:\n",
    "                    for c in client_concurrency:\n",
    "                        for b in batching:\n",
    "                            try:\n",
    "                                fn = f\"{rootdir}/{outdir}/{ns}-{st}shard-{o}-batch={b}-wrkloadbunf1-{c}-0-client0-{cl}.out\"\n",
    "                                data = batch_sizes(fn)\n",
    "                                df_file = pd.DataFrame.from_records(data)\n",
    "                                df_file[\"Ops\"] = o\n",
    "                                df_file[\"Client\"] = cl\n",
    "                                df_file[\"Concurrency\"] = c\n",
    "                                df_file[\"Commit\"] = outdir\n",
    "                                df_file[\"Batching\"] = b\n",
    "                                if batch_size_data is None:\n",
    "                                    batch_size_data = df_file\n",
    "                                else:\n",
    "                                    batch_size_data = batch_size_data.append(df_file)\n",
    "                            except:\n",
    "                                print(fn)\n",
    "\n",
    "batch_size_data\n",
    "#dfq = df.groupby([\"Commit\", \"ShardType\", \"NumShards\", \"Wrkload\", \"Concurrency\", \"Batching\", \"Ops\"]).quantile([0.05, 0.25, 0.5, 0.75, 0.95])\n",
    "#dfq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i batch_size_data -w 900 -h 600\n",
    "\n",
    "ggplot(batch_size_data, aes(x=Ops, fill=Client, group=interaction(Client,Ops))) +\n",
    "  geom_errorbar(aes(ymin=p5, ymax = p95), position=\"dodge\") +\n",
    "  geom_crossbar(aes(ymin=p25, y=p50, ymax = p75), position=\"dodge\") +\n",
    "  facet_grid(Commit~Batching)\n",
    "#  coord_cartesian(ylim=c(0, 500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With a dedicated load balancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lboutdirs = [\"kvlb-1883ee8\", \"kvlb-79b6c33\"]\n",
    "# num_shards = 2 machines, fixed\n",
    "lbops = [5000, 10000, 20000, 40000, 60000, 80000, 100000]\n",
    "lbshard_types = ['client', 'server']\n",
    "lbclients = ['10.1.1.7', '10.1.1.8', '10.1.1.9']\n",
    "lbclient_concurrency = [4, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbdf = None\n",
    "for lboutdir in lboutdirs:\n",
    "    for o in lbops:\n",
    "        for st in lbshard_types:\n",
    "            for cl in lbclients:\n",
    "                for c in lbclient_concurrency:\n",
    "                    fn = f\"{lboutdir}/{st}shard-{o}-wrkloadbunf1-{c}-client0-{cl}.data\"\n",
    "                    try:\n",
    "                        df_file = md.read_csv(fn, sep=\" \")\n",
    "                        df_file = df_file[(df_file.NumOps > 200000)]\n",
    "                        df_file[\"Commit\"] = lboutdir\n",
    "                        df_file[\"Concurrency\"] = c\n",
    "                        if lbdf is None:\n",
    "                            lbdf = df_file\n",
    "                        else:\n",
    "                            lbdf = lbdf.append(df_file)\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "lbdfq = lbdf.groupby([\"Commit\", \"ShardType\", \"NumShards\", \"Ops\", \"Concurrency\"]).quantile([0.05, 0.25, 0.5, 0.75, 0.95])\n",
    "lbdfq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbdfqu = lbdfq.unstack()\n",
    "lbdfqu.columns = [f\"{s}_{t}\" for s,t in lbdfqu.columns.values]\n",
    "lbdfqu.columns.to_flat_index()\n",
    "lbdfqu.to_csv('/tmp/kvlb-tmp.csv')\n",
    "lbdfqu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plbdf = pd.read_csv('/tmp/kvlb-tmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i plbdf -w 900 -h 600\n",
    "\n",
    "#f <- function(x) {\n",
    "#  r <- quantile(x, probs = c(0.05, 0.25, 0.5, 0.75, 0.95))\n",
    "#  names(r) <- c(\"ymin\", \"lower\", \"middle\", \"upper\", \"ymax\")\n",
    "#  r\n",
    "#}\n",
    "\n",
    "ggplot(plbdf, aes(x=Ops, fill=ShardType, group=interaction(ShardType,Ops))) +\n",
    "  geom_errorbar(aes(ymin=Latency_us_0.05, ymax = Latency_us_0.95), position=\"dodge\") +\n",
    "  geom_crossbar(aes(ymin=Latency_us_0.25, y=Latency_us_0.5, ymax = Latency_us_0.75), position=\"dodge\") +\n",
    "  facet_grid(Commit~Concurrency) +\n",
    "  coord_cartesian(ylim=c(0, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
